17/06/06 21:19:28 INFO SparkContext: Running Spark version 1.6.2
17/06/06 21:19:29 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
17/06/06 21:19:29 INFO SecurityManager: Changing view acls to: d91067
17/06/06 21:19:29 INFO SecurityManager: Changing modify acls to: d91067
17/06/06 21:19:29 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(d91067); users with modify permissions: Set(d91067)
17/06/06 21:19:29 INFO Utils: Successfully started service 'sparkDriver' on port 59253.
17/06/06 21:19:29 INFO Slf4jLogger: Slf4jLogger started
17/06/06 21:19:29 INFO Remoting: Starting remoting
17/06/06 21:19:29 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@127.0.0.1:59266]
17/06/06 21:19:29 INFO Utils: Successfully started service 'sparkDriverActorSystem' on port 59266.
17/06/06 21:19:29 INFO SparkEnv: Registering MapOutputTracker
17/06/06 21:19:29 INFO SparkEnv: Registering BlockManagerMaster
17/06/06 21:19:29 INFO DiskBlockManager: Created local directory at C:\Users\d91067\AppData\Local\Temp\blockmgr-3eb6198b-248c-4a87-90ab-bc08fcffdeb8
17/06/06 21:19:29 INFO MemoryStore: MemoryStore started with capacity 511.1 MB
17/06/06 21:19:30 INFO SparkEnv: Registering OutputCommitCoordinator
17/06/06 21:19:30 INFO Utils: Successfully started service 'SparkUI' on port 4040.
17/06/06 21:19:30 INFO SparkUI: Started SparkUI at http://127.0.0.1:4040
17/06/06 21:19:30 INFO HttpFileServer: HTTP File server directory is C:\Users\d91067\AppData\Local\Temp\spark-6542cf9e-65ac-406f-ae02-2c9f3e5e9634\httpd-ceb2516c-d87f-44f2-b75c-b1183fcf717f
17/06/06 21:19:30 INFO HttpServer: Starting HTTP Server
17/06/06 21:19:30 INFO Utils: Successfully started service 'HTTP file server' on port 59271.
17/06/06 21:19:30 INFO SparkContext: Added JAR file:/C:/Program%20Files/R/R-3.3.3/library/sparklyr/java/spark-csv_2.11-1.3.0.jar at http://127.0.0.1:59271/jars/spark-csv_2.11-1.3.0.jar with timestamp 1496776770257
17/06/06 21:19:30 INFO SparkContext: Added JAR file:/C:/Program%20Files/R/R-3.3.3/library/sparklyr/java/commons-csv-1.1.jar at http://127.0.0.1:59271/jars/commons-csv-1.1.jar with timestamp 1496776770326
17/06/06 21:19:30 INFO SparkContext: Added JAR file:/C:/Program%20Files/R/R-3.3.3/library/sparklyr/java/univocity-parsers-1.5.1.jar at http://127.0.0.1:59271/jars/univocity-parsers-1.5.1.jar with timestamp 1496776770334
17/06/06 21:19:30 INFO SparkContext: Added JAR file:/C:/Program%20Files/R/R-3.3.3/library/sparklyr/java/sparklyr-1.6-2.10.jar at http://127.0.0.1:59271/jars/sparklyr-1.6-2.10.jar with timestamp 1496776770342
17/06/06 21:19:30 INFO Executor: Starting executor ID driver on host localhost
17/06/06 21:19:30 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 59304.
17/06/06 21:19:30 INFO NettyBlockTransferService: Server created on 59304
17/06/06 21:19:30 INFO BlockManagerMaster: Trying to register BlockManager
17/06/06 21:19:30 INFO BlockManagerMasterEndpoint: Registering block manager localhost:59304 with 511.1 MB RAM, BlockManagerId(driver, localhost, 59304)
17/06/06 21:19:30 INFO BlockManagerMaster: Registered BlockManager
17/06/06 21:19:31 INFO HiveContext: Initializing execution hive, version 1.2.1
17/06/06 21:19:31 INFO ClientWrapper: Inspected Hadoop version: 2.6.0
17/06/06 21:19:31 INFO ClientWrapper: Loaded org.apache.hadoop.hive.shims.Hadoop23Shims for Hadoop version 2.6.0
17/06/06 21:19:31 INFO HiveMetaStore: 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
17/06/06 21:19:31 INFO ObjectStore: ObjectStore, initialize called
17/06/06 21:19:31 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
17/06/06 21:19:31 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
17/06/06 21:19:31 WARN Connection: BoneCP specified but not present in CLASSPATH (or one of dependencies)
17/06/06 21:19:31 WARN Connection: BoneCP specified but not present in CLASSPATH (or one of dependencies)
17/06/06 21:19:33 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
17/06/06 21:19:33 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
17/06/06 21:19:33 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
17/06/06 21:19:34 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
17/06/06 21:19:34 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
17/06/06 21:19:34 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
17/06/06 21:19:34 INFO ObjectStore: Initialized ObjectStore
17/06/06 21:19:34 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 1.2.0
17/06/06 21:19:34 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
17/06/06 21:19:34 INFO HiveMetaStore: Added admin role in metastore
17/06/06 21:19:34 INFO HiveMetaStore: Added public role in metastore
17/06/06 21:19:35 INFO HiveMetaStore: No user is added in admin role, since config is empty
17/06/06 21:19:35 INFO HiveMetaStore: 0: get_all_databases
17/06/06 21:19:35 INFO audit: ugi=d91067	ip=unknown-ip-addr	cmd=get_all_databases	
17/06/06 21:19:35 INFO HiveMetaStore: 0: get_functions: db=default pat=*
17/06/06 21:19:35 INFO audit: ugi=d91067	ip=unknown-ip-addr	cmd=get_functions: db=default pat=*	
17/06/06 21:19:35 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MResourceUri" is tagged as "embedded-only" so does not have its own datastore table.
17/06/06 21:19:36 INFO SessionState: Created local directory: C:/Users/d91067/AppData/Local/Temp/9585098e-e797-4161-9cec-474cddc3652f_resources
17/06/06 21:19:36 INFO SessionState: Created HDFS directory: C:/Users/d91067/AppData/Local/rstudio/spark/Cache/spark-1.6.2-bin-hadoop2.6/tmp/hive/d91067/9585098e-e797-4161-9cec-474cddc3652f
17/06/06 21:19:36 INFO SessionState: Created local directory: C:/Users/d91067/AppData/Local/rstudio/spark/Cache/spark-1.6.2-bin-hadoop2.6/tmp/hive/9585098e-e797-4161-9cec-474cddc3652f
17/06/06 21:19:36 INFO SessionState: Created HDFS directory: C:/Users/d91067/AppData/Local/rstudio/spark/Cache/spark-1.6.2-bin-hadoop2.6/tmp/hive/d91067/9585098e-e797-4161-9cec-474cddc3652f/_tmp_space.db
17/06/06 21:19:36 INFO HiveContext: default warehouse location is C:\Users\d91067\AppData\Local\rstudio\spark\Cache\spark-1.6.2-bin-hadoop2.6\tmp\hive
17/06/06 21:19:36 INFO HiveContext: Initializing HiveMetastoreConnection version 1.2.1 using Spark classes.
17/06/06 21:19:36 INFO ClientWrapper: Inspected Hadoop version: 2.6.0
17/06/06 21:19:36 INFO ClientWrapper: Loaded org.apache.hadoop.hive.shims.Hadoop23Shims for Hadoop version 2.6.0
17/06/06 21:19:36 INFO HiveMetaStore: 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
17/06/06 21:19:36 INFO ObjectStore: ObjectStore, initialize called
17/06/06 21:19:36 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
17/06/06 21:19:36 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
17/06/06 21:19:36 WARN Connection: BoneCP specified but not present in CLASSPATH (or one of dependencies)
17/06/06 21:19:36 WARN Connection: BoneCP specified but not present in CLASSPATH (or one of dependencies)
17/06/06 21:19:37 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
17/06/06 21:19:38 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
17/06/06 21:19:38 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
17/06/06 21:19:38 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
17/06/06 21:19:38 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
17/06/06 21:19:38 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
17/06/06 21:19:38 INFO ObjectStore: Initialized ObjectStore
17/06/06 21:19:38 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 1.2.0
17/06/06 21:19:38 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
17/06/06 21:19:38 INFO HiveMetaStore: Added admin role in metastore
17/06/06 21:19:38 INFO HiveMetaStore: Added public role in metastore
17/06/06 21:19:38 INFO HiveMetaStore: No user is added in admin role, since config is empty
17/06/06 21:19:39 INFO HiveMetaStore: 0: get_all_databases
17/06/06 21:19:39 INFO audit: ugi=d91067	ip=unknown-ip-addr	cmd=get_all_databases	
17/06/06 21:19:39 INFO HiveMetaStore: 0: get_functions: db=default pat=*
17/06/06 21:19:39 INFO audit: ugi=d91067	ip=unknown-ip-addr	cmd=get_functions: db=default pat=*	
17/06/06 21:19:39 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MResourceUri" is tagged as "embedded-only" so does not have its own datastore table.
17/06/06 21:19:39 INFO SessionState: Created local directory: C:/Users/d91067/AppData/Local/Temp/95b2bd5b-84ad-4937-a783-580641b07fd9_resources
17/06/06 21:19:39 INFO SessionState: Created HDFS directory: C:/Users/d91067/AppData/Local/rstudio/spark/Cache/spark-1.6.2-bin-hadoop2.6/tmp/hive/d91067/95b2bd5b-84ad-4937-a783-580641b07fd9
17/06/06 21:19:39 INFO SessionState: Created local directory: C:/Users/d91067/AppData/Local/rstudio/spark/Cache/spark-1.6.2-bin-hadoop2.6/tmp/hive/95b2bd5b-84ad-4937-a783-580641b07fd9
17/06/06 21:19:39 INFO SessionState: Created HDFS directory: C:/Users/d91067/AppData/Local/rstudio/spark/Cache/spark-1.6.2-bin-hadoop2.6/tmp/hive/d91067/95b2bd5b-84ad-4937-a783-580641b07fd9/_tmp_space.db
