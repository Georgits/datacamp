{
    "collab_server" : "",
    "contents" : "library(readxl)\nlibrary(ggplot2)\nlibrary(forecast)\nlibrary(fpp)\nlibrary(fpp2)\n\n# 1. Chapter: Exploring and visualizing time series in R ----\n  # Creating time series objects in R ----\n  # Read the data from Excel into R\n  mydata <- read_excel(\"exercise1.xlsx\")\n  \n  # Create a ts object called myts\n  myts <- ts(mydata[,-1], start = c(1981, 1), frequency = 4)\n  \n  \n  # Time series plots ----\n  # Plot the data with facetting\n  autoplot(myts, facets = TRUE)\n  \n  # Plot the data without facetting\n  autoplot(myts, facets = FALSE)\n  \n  # Plot the four series\n  autoplot(gold, facets = FALSE)\n  autoplot(woolyrnq, facets = FALSE)\n  autoplot(gas, facets = FALSE)\n  autoplot(taylor, facets = FALSE)\n  \n  # Find the outlier in the gold series\n  goldoutlier <- which.max(gold)\n  \n  # Create a vector of the seasonal frequencies of gold, woolyrnq, gas, and taylor\n  frequency(gold)\n  frequency(woolyrnq)\n  frequency(gas)\n  frequency(taylor)\n  \n  freq <- c(1, 4, 12, 336)\n  \n  \n  \n  # Seasonal plots ----\n  # a plots of the a10 data\n  autoplot(a10, facets = TRUE)\n  ggseasonplot(a10)\n  \n  # Produce a polar coordinate season plot for the a10 data\n  ggseasonplot(a10, polar = TRUE)\n  \n  # Restrict the ausbeer data to start in 1992\n  beer <- window(ausbeer, start = 1992)\n  \n  # Make plots of the beer data\n  autoplot(beer, facets = TRUE)\n  ggsubseriesplot(beer)\n  \n  \n  \n  # Autocorrelation of non-seasonal time series ----\n  # Create an autoplot of the oil data\n  autoplot(oil)\n  \n  # Create a lag plot of the oil data\n  gglagplot(oil, 9)\n  \n  # Create an ACF plot of the oil data\n  ggAcf(oil)\n  \n  \n  \n  # Autocorrelation of seasonal and cyclic time series ----\n  # Plot the annual sunspot numbers\n  autoplot(sunspot.year)\n  ggAcf(sunspot.year)\n  \n  # Save the lag corresponding to maximum autocorrelation\n  maxlag_sunspot <- 1\n  \n  # Plot the traffic on the Hyndsight blog\n  autoplot(hyndsight)\n  ggAcf(hyndsight)\n  \n  # Save the lag corresponding to maximum autocorrelation\n  maxlag_hyndsight <- 7\n  \n  \n  \n  \n  # Stock prices and white noise ----\n  # Plot the original series\n  autoplot(goog)\n  \n  # Plot the differenced series\n  autoplot(diff(goog))\n  \n  # ACF of the differenced series\n  ggAcf(diff(goog))\n  \n  # Ljung-Box test of the differenced series\n  Box.test(diff(goog), lag = 10, type = \"Ljung\")\n  \n  \n  \n  \n  \n# 2. Chapter: Benchmark methods and forecast accuracy ----\n  # Naive forecasting methods ----\n  # Use naive() to forecast the goog series\n  fcgoog <- naive(goog, 20)\n  \n  # Plot and summarize the forecasts\n  autoplot(fcgoog)\n  summary(fcgoog)\n  \n  # Use snaive() to forecast the ausbeer series\n  fcbeer <- snaive(ausbeer, 16)\n  \n  # Plot and summarize the forecasts\n  autoplot(fcbeer)\n  summary(fcbeer)\n  \n  \n  \n  # Checking time series residuals ----\n  # Check the residuals from the naive forecasts applied to the goog series\n  goog %>% naive() %>% checkresiduals()\n  \n  # Do they look like white noise (TRUE or FALSE)\n  googwn <- TRUE\n  \n  # Check the residuals from the seasonal naive forecasts applied to the ausbeer series\n  ausbeer %>% snaive() %>% checkresiduals()\n  \n  # Do they look like white noise (TRUE or FALSE)\n  beerwn <- FALSE\n  \n  \n  \n  \n  # Evaluating forecast accuracy of non-seasonal methods ----\n  # Create the training data as train\n  train <- subset.ts(gold, end = 1000)\n  \n  # Compute naive forecasts and save to naive_fc\n  naive_fc <- naive(train, h = 108)\n  \n  # Compute mean forecasts and save to mean_fc\n  mean_fc <- meanf(train, h = 108)\n  \n  # Use accuracy() to compute RMSE statistics\n  accuracy(naive_fc, gold)\n  accuracy(mean_fc, gold)\n  \n  # Assign one of the two forecasts as bestforecasts\n  bestforecasts <- naive_fc\n  \n  \n  \n  # Evaluating forecast accuracy of seasonal methods ----\n  # Create three training series omitting the last 1, 2, and 3 years\n  train1 <- window(vn[, \"Melbourne\"], end = c(2010, 4))\n  train2 <- window(vn[, \"Melbourne\"], end = c(2009, 4))\n  train3 <- window(vn[, \"Melbourne\"], end = c(2008, 4))\n  \n  # Produce forecasts using snaive()\n  fc1 <- snaive(train1, h = 4)\n  fc2 <- snaive(train2, h = 4)\n  fc3 <- snaive(train3, h = 4)\n  \n  # Use accuracy() to compare the MAPE of each series\n  accuracy(fc1, vn[, \"Melbourne\"])[\"Test set\", \"MAPE\"]\n  accuracy(fc2, vn[, \"Melbourne\"])[\"Test set\", \"MAPE\"]\n  accuracy(fc3, vn[, \"Melbourne\"])[\"Test set\", \"MAPE\"]\n  \n  \n  \n  \n  \n  # Using tsCV() for time series cross-validation ----\n  # Compute cross-validated errors for up to 8 steps ahead\n  e <- matrix(NA_real_, nrow = 1000, ncol = 8)\n  for (h in 1:8)\n    e[, h] <- tsCV(goog, naive, h = h)\n  \n  # Compute the MSE values and remove missing values\n  mse <- colMeans(e^2, na.rm = TRUE)\n  \n  # Plot the MSE values (y) against the forecast horizon (x)\n  data.frame(h = 1:8, MSE = mse) %>%\n    ggplot(aes(x = h, y = MSE)) + geom_point()\n  \n  \n  \n  \n# 3. Chapter: Exponential smoothing ----\n  # Simple exponential smoothing ----\n  # Use ses() to forecast the next 10 years of winning times\n  fc <- ses(marathon, h = 10)\n  \n  # Use summary() to see the model parameters\n  summary(fc)\n  \n  # Use autoplot() to plot the forecasts\n  autoplot(fc)\n  \n  # Add the one-step forecasts for the training data to the plot\n  autoplot(fc) + autolayer(fitted(fc))\n  \n  \n  \n  # SES vs naive ----\n  # Create a training set using subset()\n  train <- subset(marathon, end = length(marathon) - 20)\n  \n  # Compute SES and naive forecasts, and save to fcses and fcnaive\n  fcses <- ses(train, h = 20)\n  fcnaive <- naive(train, h = 20)\n  \n  # Calculate forecast accuracy measures\n  accuracy(fcses, marathon)\n  accuracy(fcnaive, marathon)\n  \n  # Save the better forecasts as fcbest\n  fcbest <- fcnaive\n  \n  \n  \n  \n  # Holt's trend methods ----\n  # Produce 10 year forecasts of austa using holt()\n  fcholt <- holt(austa, h = 10)\n  \n  # Look at fitted model using summary()\n  summary(fcholt)\n  \n  # Plot the forecasts\n  autoplot(fcholt)\n  \n  # Check that the residuals look like white noise\n  checkresiduals(fcholt)\n  \n  \n  \n  # Holt-Winters with monthly data ----\n  # Plot the data\n  autoplot(a10)\n  \n  # Produce 3 year forecasts\n  fc <- hw(a10, h = 36, seasonal = \"multiplicative\")\n  \n  # Check residuals look like white noise (set whitenoise to be TRUE or FALSE)\n  checkresiduals(fc)\n  whitenoise <- FALSE\n  \n  # Plot forecasts\n  autoplot(fc)\n  \n  \n  \n  # Holt-Winters method with daily data ----\n  # Create training data with subset()\n  train <- subset(hyndsight, end = length(hyndsight) - 28)\n  \n  # Holt-Winters additive forecasts as fchw\n  fchw <- hw(train, seasonal = \"additive\", h = 28)\n  \n  # Seasonal naive forecasts as fcsn\n  fcsn <- snaive(train, h = 28)\n  \n  # Find better forecasts with accuracy()\n  accuracy(fchw, hyndsight)\n  accuracy(fcsn, hyndsight)\n  \n  # Plot the better forecasts\n  autoplot(fchw)\n  \n  \n  \n  # Automatic forecasting with exponential smoothing ----\n  # Fit ETS model to austa in fitaus\n  fitaus <- ets(austa)\n  \n  # Check residuals\n  checkresiduals(fitaus)\n  \n  # Plot forecasts\n  autoplot(forecast(fitaus))\n  \n  # Repeat for hyndsight data in fiths\n  fiths <- ets(hyndsight)\n  checkresiduals(fiths)\n  autoplot(forecast(fiths))\n  \n  # Which model(s) fails test? (TRUE or FALSE)\n  fitausfail <- FALSE\n  fithsfail <- TRUE\n  \n  \n  \n  # ets vs snaive ----\n  # Function to return ETS forecasts\n  fets <- function(y, h) {\n    forecast(ets(y), h = h)\n  }\n  \n  # Apply tsCV() for both methods\n  e1 <- tsCV(cement, fets, h = 4)\n  e2 <- tsCV(cement, snaive, h = 4)\n  \n  # Compute MSE of resulting errors (watch out for missing values)\n  mean(e1^2, na.rm = TRUE)\n  mean(e2^2, na.rm = TRUE)\n  \n  # Best the better MSE as bestmse\n  bestmse <- mean(e2^2, na.rm = TRUE)\n  \n  \n  \n  \n  # When does ets fail? ----\n  # It's important to realize that ETS doesn't work for all cases. \n  # Plot the lynx series\n  autoplot(lynx)\n  \n  # Use ets() to model the lynx series\n  fit <- ets(lynx)\n  \n  # Use summary() to look at model and parameters\n  summary(fit)\n  \n  # Plot 20-year forecasts of the lynx series\n  lynx %>% ets() %>% forecast(h = 20) %>% autoplot()\n  \n  \n  \n  \n  \n  \n  \n# 3. Chapter: Forecasting with ARIMA models  ----\n  # Box-Cox transformations for time series ----\n  # Plot the series\n  autoplot(a10)\n  \n  # Try four values of lambda in Box-Cox transformations\n  a10 %>% BoxCox(lambda = 0) %>% autoplot()\n  a10 %>% BoxCox(lambda = 1) %>% autoplot()\n  a10 %>% BoxCox(lambda = -1) %>% autoplot()\n  a10 %>% BoxCox(lambda = 2) %>% autoplot()\n  \n  # Compare with BoxCox.lambda()\n  BoxCox.lambda(a10)\n  \n  \n  \n  # Non-seasonal differencing for stationarity ----\n  # Plot the US female murder rate\n  autoplot(wmurders)\n  \n  # Plot the differenced murder rate\n  autoplot(diff(wmurders))\n  \n  # Plot the ACF of the differenced murder rate\n  ggAcf(diff(wmurders))\n  \n  \n  \n  # Seasonal differencing for stationarity ----\n  # Plot the data\n  autoplot(h02)\n  \n  # Take logs and seasonal differences of h02\n  difflogh02 <- diff(log(h02), lag = 12)\n  \n  # Plot the resulting logged and differenced data\n  autoplot(difflogh02)\n  \n  # Take another difference and plot\n  ddifflogh02 <- diff(difflogh02)\n  autoplot(ddifflogh02)\n  \n  # Plot ACF of final series ddifflogh02\n  ggAcf(ddifflogh02)\n  \n  \n  \n  \n  # Automatic ARIMA models for non-seasonal time series ----\n  # Fit an automatic ARIMA model to the austa series\n  fit <- auto.arima(austa)\n  \n  # Check the residuals look like white noise (set residualsok to TRUE or FALSE)\n  checkresiduals(fit)\n  residualsok <- TRUE\n  \n  # Summarize the model\n  summary(fit)\n  \n  # Find the AICc value and the number of differences used\n  AICc <- -14.46\n  d <- 1\n  \n  # Plot forecasts of fit\n  fit %>% forecast(h = 10) %>% autoplot()\n  \n  \n  \n  # Forecasting with ARIMA models ----\n  # Plot forecasts from an ARIMA(0,1,1) model with no drift\n  austa %>% Arima(order = c(0, 1, 1), include.constant = FALSE) %>% forecast() %>% autoplot()\n  \n  # Plot forecasts from an ARIMA(2,1,3) model with drift\n  austa %>% Arima(order = c(2, 1, 3), include.constant = TRUE) %>% forecast() %>% autoplot()\n  \n  # Plot forecasts from an ARIMA(0,0,1) model with a constant.\n  austa %>% Arima(order = c(0, 0, 1), include.constant = TRUE) %>% forecast() %>% autoplot()\n  \n  # Plot forecasts from an ARIMA(0,2,1) model with no constant.\n  austa %>% Arima(order = c(0, 2, 1), include.constant = FALSE) %>% forecast() %>% autoplot()\n  \n  \n  \n  \n  # Comparing auto.arima() and ets() on non-seasonal data ----\n  # Set up forecast functions for ETS and ARIMA models\n  fets <- function(x, h) {\n    forecast(ets(x), h = h)\n  }\n  farima <- function(x, h) {\n    forecast(auto.arima(x), h = h)\n  }\n  \n  # Compute CV errors for ETS as e1\n  e1 <- tsCV(austa, fets, h = 1)\n  \n  # Compute CV errors for ARIMA as e2\n  e2 <- tsCV(austa, farima, h = 1)\n  \n  # Find MSE of each model class\n  mean(e1^2, na.rm = TRUE)\n  mean(e2^2, na.rm = TRUE)\n  \n  # Plot 10-year forecasts using the best model class\n  austa %>% auto.arima() %>% forecast(h = 10) %>% autoplot()\n  \n  \n  \n  \n  # Automatic ARIMA models for seasonal time series ----\n  # Check that the logged h02 data have stable variance\n  h02 %>% log() %>% autoplot()\n  \n  # Fit a seasonal ARIMA model to h02 with lambda = 0\n  fit <- auto.arima(h02, lambda = 0)\n  \n  # Summarize the fitted model\n  summary(fit)\n  \n  # Record the amount of lag-1 differencing and seasonal differencing used\n  d <- 1\n  D <- 1\n  \n  # Plot 2-year forecasts\n  fit %>% forecast(h = 24) %>% autoplot()\n  \n  \n  \n  # Exploring auto.arima options ----\n  # Use the default options to find an ARIMA model for euretail\n  fit1 <- auto.arima(euretail)\n  \n  # Don't use a stepwise search.\n  fit2 <- auto.arima(euretail, stepwise = FALSE)\n  \n  # AICc of best model\n  summary(fit2)\n  AICc <- 68.39\n  \n  # Compute 2-year forecasts from best model\n  euretail %>% auto.arima(stepwise = FALSE) %>% forecast(h = 8) %>% autoplot()\n  \n  \n  \n  # Comparing auto.arima() and ets() on seasonal data ----\n  # Use 20 years of the qcement data beginning in 1988\n  train <- window(qcement, start = 1988, end = c(2007, 4))\n  \n  # Fit an ARIMA and an ETS model to the training data\n  fit1 <- ets(train)\n  fit2 <- auto.arima(train)\n  \n  # Check that both models have white noise residuals\n  checkresiduals(fit1)\n  checkresiduals(fit2)\n  \n  # Produce forecasts for each model\n  fc1 <- forecast(fit1, h = 25)\n  fc2 <- forecast(fit2, h = 25)\n  \n  # Use accuracy() to find best model based on MSE\n  accuracy(fc1, qcement)\n  accuracy(fc2, qcement)\n  best <- fc1\n  \n  \n  \n  \n  \n# 5. Chapter: Advanced methods  -----\n  # Forecasting sales allowing for advertising expenditure ----\n  # Time plot of both variables\n  autoplot(advert, facets = TRUE)\n  \n  # Fit ARIMA model\n  fit <- auto.arima(advert[, \"sales\"], xreg = advert[, \"advert\"], stationary = TRUE)\n  \n  # Check model. Increase in sales for each unit increase in advertising\n  salesincrease <-coefficients(fit)[3]\n  \n  # Forecast fit as fc\n  fc <- forecast(fit, xreg = rep(10,6))\n  \n  # Plot forecasts\n  autoplot(fc) + xlab(\"Year\") + ylab(\"Sales\")\n  \n  \n  \n  # Forecasting electricity demand ----\n  # Time plots of demand and temperatures\n  autoplot(elec[, c(\"Demand\", \"Temperature\")], facets = TRUE)\n  \n  # Matrix of regressors\n  xreg <- cbind(MaxTemp = elec[, \"Temperature\"], \n                MaxTempSq = elec[, \"Temperature\"]^2, \n                Workday = elec[, \"Workday\"])\n  \n  # Fit model\n  fit <- auto.arima(elec[, \"Demand\"], xreg = xreg)\n  \n  # Forecast one day ahead\n  forecast(fit, xreg = cbind(20, 20^2, 1))\n  \n  \n  \n  # Forecasting weekly data ----\n  # Set up harmonic regressors of order 13\n  harmonics <- fourier(gasoline, K = 13)\n  \n  # Fit regression model with ARIMA errors\n  # FALSE, weil die Saisonalitaet schon durch Fourier-Transformation modelliert wird\n  fit <- auto.arima(gasoline, xreg = harmonics, seasonal = FALSE)\n  \n  # Forecasts next 3 years\n  newharmonics <- fourier(gasoline, K = 13, h = 3 * 52)\n  fc <- forecast(fit, xreg = newharmonics)\n  \n  # Plot forecasts\n  autoplot(fc)\n  \n  \n  \n  \n  # Harmonic regression for multiple seasonality ----\n  # Fit a harmonic regression using order 10 for each type of seasonality.\n  fit <- tslm(taylor ~ fourier(taylor, K = c(10, 10)))\n  \n  # Forecast 20 working days ahead\n  fc <- forecast(fit, newdata = data.frame(fourier(taylor, K = c(10, 10), h = 20 * 48)))\n  \n  # Plot the forecasts\n  autoplot(fc)\n  \n  # Check the residuals\n  checkresiduals(fit)\n  \n  \n  \n  \n  # Forecasting call bookings ----\n  # Plot the calls data\n  autoplot(calls)\n  \n  # Set up the xreg matrix\n  xreg <- fourier(calls, K = c(10,0))\n  \n  # Fit a dynamic regression model\n  fit <- auto.arima(calls, xreg = xreg, seasonal = FALSE, stationary = TRUE)\n  \n  # Check the residuals\n  checkresiduals(fit)\n  \n  # Plot forecasts for 10 working days ahead\n  fc <- forecast(fit, xreg =  fourier(calls, c(10, 0), 1690))\n  autoplot(fc)\n  \n  \n  \n  \n  \n  # TBATS models for electricity demand ----\n  # Plot the gas data\n  autoplot(gas)\n  \n  # Fit a TBATS model to the gas data\n  fit <- tbats(gas)\n  \n  # Forecast the series for the next 5 years\n  fc <- forecast(fit, h = 5 * 12)\n  \n  # Plot the forecasts\n  autoplot(fc)\n  \n  # Record the Box-Cox parameter and the order of the Fourier terms\n  lambda <- 0.082\n  K <- 5",
    "created" : 1496349451768.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "3958249797",
    "id" : "3B067196",
    "lastKnownWriteTime" : 1496665090,
    "last_content_update" : 1496665090679,
    "path" : "C:/Users/d91067/Desktop/datacamp/Forecasting/Forecasting_using_R.R",
    "project_path" : "Forecasting_using_R.R",
    "properties" : {
        "source_window_id" : "",
        "tempName" : "Untitled1"
    },
    "relative_order" : 1,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_source"
}