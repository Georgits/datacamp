{
    "collab_server" : "",
    "contents" : "# 3. Chapter 3 ----\n# 3.1 PCA using prcomp() ----\n    # Perform scaled PCA: pr.out\n    pr.out <- prcomp(iris[-5], scale = TRUE, center = TRUE)\n    \n    # Inspect model output\n    summary(pr.out)\n    \n    # plot model output\n    biplot(pr.out)\n    \n    # pront the pc-results\n    pr.out$x\n    \n    \n    # Variability of each principal component: pr.var\n    pr.var <- pr.out$sdev^2\n    \n    # Variance explained by each principal component: pve\n    pve <- pr.var / sum(pr.var)\n    \n    # Visualize variance explained\n    # Plot variance explained for each principal component\n    plot(pve, xlab = \"Principal Component\",\n         ylab = \"Proportion of Variance Explained\",\n         ylim = c(0, 1), type = \"b\")\n    \n    # Plot cumulative proportion of variance explained\n    plot(cumsum(pve), xlab = \"Principal Component\",\n         ylab = \"Cummulative Proportion of Variance Explained\",\n         ylim = c(0, 1), type = \"b\")\n    \n    \n\n    \n# 3.2 Practical issues: scaling ----\n    # PCA model with scaling: pr.with.scaling\n    pr.with.scaling <- prcomp(iris[-5], scale = TRUE)\n    \n    # PCA model without scaling: pr.without.scaling\n    pr.without.scaling <- prcomp(iris[-5], scale = FALSE)\n    \n    # Create biplots of both for comparison\n    biplot(pr.with.scaling)\n    biplot(pr.without.scaling)\n    \n\n    \n# 4. Chapter 4 ----    \n# 4.1 Preparing the data ----\n    url <- \"http://s3.amazonaws.com/assets.datacamp.com/production/course_1903/datasets/WisconsinCancer.csv\"\n    \n    # Download the data: wisc.df\n    wisc.df <- read.csv(url)\n    \n    # Convert the features of the data: wisc.data\n    wisc.data <- as.matrix(wisc.df[,3:32])\n    \n    # Set the row names of wisc.data\n    row.names(wisc.data) <- wisc.df$id\n    \n    # Create diagnosis vector\n    diagnosis <- as.numeric(wisc.df$diagnosis == \"M\")\n    \n# 4.2 Performing PCA ----\n    # Check column means and standard deviations\n    colMeans(wisc.data)\n    apply(wisc.data, 2, sd)\n    \n    # Execute PCA, scaling if appropriate: wisc.pr\n    wisc.pr <- prcomp(wisc.data, scale = TRUE)\n    \n    # Look at summary of results\n    summary(wisc.pr)\n    \n    \n# 4.2 Interpreting PCA results ----\n    # Create a biplot of wisc.pr\n    biplot(wisc.pr)\n    \n    # Scatter plot observations by components 1 and 2\n    plot(wisc.pr$x[, c(1, 2)], col = (diagnosis + 1), \n         xlab = \"PC1\", ylab = \"PC2\")\n    \n    # Repeat for components 1 and 3\n    plot(wisc.pr$x[, c(1, 3)], col = (diagnosis + 1), \n         xlab = \"PC1\", ylab = \"PC3\")\n    \n\n# 4.3 Variance explained ----\n    par(mfrow = c(1, 2))\n    \n    # Calculate variability of each component\n    pr.var <- wisc.pr$sdev^2\n    \n    # Variance explained by each principal component: pve\n    pve <- pr.var / sum(pr.var)\n    \n    # Plot variance explained for each principal component\n    plot(pve, xlab = \"Principal Component\", \n         ylab = \"Proportion of Variance Explained\", \n         ylim = c(0, 1), type = \"b\")\n    \n    # Plot cumulative proportion of variance explained\n    plot(cumsum(pve), xlab = \"Principal Component\", \n         ylab = \"Cummulative Proportion of Variance Explained\", \n         ylim = c(0, 1), type = \"b\")\n    \n\n# 4.4 Hierarchical clustering of case data ----\n    # Scale the wisc.data data: data.scaled\n    data.scaled <- scale(wisc.data)\n    \n    # Calculate the (Euclidean) distances: data.dist\n    data.dist <- dist(data.scaled)\n    \n    # Create a hierarchical clustering model: wisc.hclust\n    wisc.hclust <- hclust(data.dist, method = \"complete\")\n    \n\n# 4.5 Selecting number of clusters ----\n    # Cut tree so that it has 4 clusters: wisc.hclust.clusters\n    wisc.hclust.clusters <- cutree(wisc.hclust, h = 20)\n    \n    # Compare cluster membership to actual diagnoses\n    table(wisc.hclust.clusters, diagnosis)\n\n    \n# 4.6 k-means clustering and comparing results ----\n    # Create a k-means model on wisc.data: wisc.km\n    wisc.km <- kmeans(scale(wisc.data), centers = 2, nstart = 20)\n    \n    # Compare k-means to actual diagnoses\n    table(wisc.km$cluster, diagnosis)\n    \n    # Compare k-means to hierarchical clustering\n    table(wisc.km$cluster, wisc.hclust.clusters)\n    \n    \n# 4.7 Clustering on PCA results ----\n    # Create a hierarchical clustering model: wisc.pr.hclust\n    wisc.pr.hclust <- hclust(dist(wisc.pr$x[, 1:7]), method = \"complete\")\n    \n    # Cut model into 4 clusters: wisc.pr.hclust.clusters\n    wisc.pr.hclust.clusters <- cutree(wisc.pr.hclust, k = 4)\n    \n    # Compare to actual diagnoses\n    table(wisc.pr.hclust.clusters, diagnosis)\n    \n    # Compare to k-means and hierarchical\n    table(wisc.km$cluster, diagnosis)\n    table(wisc.hclust.clusters, diagnosis)",
    "created" : 1491059006612.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "3660429966",
    "id" : "300FEB66",
    "lastKnownWriteTime" : 1491081071,
    "last_content_update" : 1491081071861,
    "path" : "C:/Users/d91067/Desktop/datacamp/01_R/MachineLearning/01_Unsupervised_Learning_in_R.R",
    "project_path" : "01_Unsupervised_Learning_in_R.R",
    "properties" : {
        "tempName" : "Untitled1"
    },
    "relative_order" : 1,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_source"
}